{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the dependences \n",
    "from langchain.chains import LLMChain , SequentialChain \n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Openai API and Base link \n",
    "\n",
    "API_KEY = api_key\n",
    "BASE_URL = \"https://api.sree.shop/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a llm of model\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key = API_KEY,\n",
    "    base_url = BASE_URL,\n",
    "    model_name = 'gpt-4o',\n",
    "    temperature = 0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create json format in which we need output \n",
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\" : \"Choice the correct answer?\",\n",
    "        \"options\" : {\n",
    "            'a' : 'choice here',\n",
    "            'b' : 'choice here',\n",
    "            'c' : 'choice here',\n",
    "            'd' : 'choice here',        \n",
    "        },\n",
    "        \"correct answer\" : \"correct answer here\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\" : \"Choice the correct answer?\",\n",
    "        \"options\" : {\n",
    "            'a' : 'choice here',\n",
    "            'b' : 'choice here',\n",
    "            'c' : 'choice here',\n",
    "            'd' : 'choice here',        \n",
    "        },\n",
    "        \"correct answer\" : \"correct answer here\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\" : \"Choice the correct answer?\",\n",
    "        \"options\" : {\n",
    "            'a' : 'choice here',\n",
    "            'b' : 'choice here',\n",
    "            'c' : 'choice here',\n",
    "            'd' : 'choice here',        \n",
    "        },\n",
    "        \"correct answer\" : \"correct answer here\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a template of input\n",
    "Template = \"\"\"\n",
    "Text: {text}\n",
    "You are an Expert MCQ maker. We gave you a text above. Make {number} MCQs from the given text for {subject} to a student with the difficulty of {tone}. \n",
    "Make sure all the MCQs are not repeated and confirm from the text as well. \n",
    "Ensure your response follows this template: RESPONE_JSON. Ensure the MCQs count matches {number}.\n",
    "{response_json}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_prompt = PromptTemplate(\n",
    "    input_variables = ['text' , 'number' ,'subject', 'tone', 'response_json'],\n",
    "    template = Template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_chain = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = student_prompt,\n",
    "    output_key = 'quiz',\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define second template for evaluating 1st response\n",
    "Template2 = \"\"\"\n",
    "You are an expert writer and examiner of {subject} for students.\n",
    "You need to evaluate the complexity of the MCQs and analyze them.\n",
    "Use a maximum of 50 words to analyze the complexity. \n",
    "If the quiz is not appropriate for the cognitive and analytical abilities of the students, modify the questions to fit the required tone.\n",
    "Quiz questions: {quiz}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_prompt = PromptTemplate(\n",
    "    input_variables = ['subject' , 'quiz'],\n",
    "    template = Template2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_chain = LLMChain(\n",
    "    llm = llm, \n",
    "    prompt = teacher_prompt, \n",
    "    output_key = 'review',\n",
    "    verbose = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a sequential chain for combing both respones \n",
    "final_chain = SequentialChain(\n",
    "    chains = [student_chain , teacher_chain],\n",
    "    input_variables = ['text' , 'number' ,'subject', 'tone', 'response_json'],\n",
    "    output_variables = ['quiz' , 'review'],\n",
    "    verbose = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a file \n",
    "file_path = r\"C:\\Users\\SAJID HAMEED\\Desktop\\AI_WorkShop\\AI_with_hugging_face\\data.txt\"\n",
    "with open(file_path , 'r') as file:\n",
    "    Text = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializing the python dictionary in to json format\n",
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets input variables \n",
    "Number = 5 \n",
    "Subject = 'machine learning'\n",
    "Tone = 'Simple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = final_chain(\n",
    "    {\n",
    "        'text' : Text,\n",
    "        'subject': Subject,\n",
    "        'number' : Number,\n",
    "        'tone' : Tone,\n",
    "        'response_json' : RESPONSE_JSON\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz = response.get('quiz')\n",
    "print(quiz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
